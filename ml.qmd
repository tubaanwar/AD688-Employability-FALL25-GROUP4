---
title: "Machine Learning Methods"
subtitle: "Clustering and Classification for Job Market Analysis"
format: 
  html:
    toc: true
    number-sections: true
    df-print: paged
    code-overflow: wrap
    embed-resources: true
    css: styles.css 
jupyter: python3
execute:
  echo: true
  eval: true
  warning: false
  message: false
---

## Introduction

This section applies machine learning techniques to uncover patterns in job market data, with a specific focus on Business Analytics, Data Science, and Machine Learning roles. As job seekers entering these competitive fields in 2024, understanding the hidden structures in job postings and identifying role characteristics can provide strategic advantages in career planning.

We employ two complementary machine learning approaches:

1. K-Means Clustering: To discover natural groupings in BA/DS/ML job postings
2. Classification Models: To distinguish between different role types

```{python}
#| label: setup
#| echo: false

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (accuracy_score, f1_score, classification_report, 
                             confusion_matrix, roc_curve, auc, roc_auc_score)
from sklearn.preprocessing import label_binarize
from itertools import cycle
import warnings
warnings.filterwarnings('ignore')


# Set style with pink, purple, red, blue colors
sns.set_style("whitegrid")
custom_colors = ['#E91E63', '#9B59B6', '#F44336', '#2196F3']
sns.set_palette(custom_colors)

# Load cleaned data
df = pd.read_csv('cleanedjob_postings.csv')
print(f"Dataset loaded: {df.shape[0]:,} rows, {df.shape[1]} columns")
```

## Data Filtering for BA/DS/ML Analysis

To focus our analysis on relevant career paths for Business Analytics (BA), Data Science (DS), and Machine Learning (ML) professionals, we filter the dataset to include only positions matching these disciplines. Number of filtered jobs for BA/DS/ML are 15,378. This is around 25.97% of the data

```{python}
#| echo: true
#| eval: true

# Define keywords for BA/DS/ML roles
ba_ds_ml_keywords = [
    'data scientist', 'data science', 'machine learning', 'ml engineer',
    'business analyst', 'business analytics', 'data analyst', 'data analytics',
    'ai engineer', 'artificial intelligence', 'deep learning', 
    'quantitative analyst', 'analytics', 'statistician', 'research scientist'
]

# Filter based on job titles
mask = df['TITLE_NAME'].str.lower().str.contains(
    '|'.join(ba_ds_ml_keywords), 
    na=False, 
    regex=True
)
df_filtered = df[mask].copy()

job_title_head = df_filtered['TITLE_NAME'].value_counts().head(10)

job_title_head.to_csv("./_output/Filtered_Job_Titles.csv")
```

```{python}
#| echo: true
#| eval: true

import pandas

job_titles = pd.read_csv("./_output/Filtered_Job_Titles.csv")
# hide index pandas

job_titles.style.hide(axis="index")

```

## Feature Engineering

Before applying machine learning algorithms, we need to prepare our features. We'll focus on quantitative measures that can help us understand job characteristics.

```{python}
#| echo: true
#| eval: true

# Calculate average salary if not already present
if 'AVG_SALARY' not in df_filtered.columns:
    # Create synthetic salary data for demonstration
    # In real analysis, you would have actual salary data
    np.random.seed(42)
    df_filtered['AVG_SALARY'] = np.random.normal(95000, 25000, len(df_filtered))
    df_filtered['AVG_SALARY'] = df_filtered['AVG_SALARY'].clip(lower=40000, upper=200000)

# Create experience level from MIN_YEARS_EXPERIENCE
df_filtered['EXPERIENCE_YEARS'] = df_filtered['MIN_YEARS_EXPERIENCE'].fillna(0)

# Convert DURATION to numeric (days)
df_filtered['DURATION_DAYS'] = pd.to_numeric(df_filtered['DURATION'], errors='coerce').fillna(30)

# Create binary remote indicator
df_filtered['IS_REMOTE'] = (df_filtered['REMOTE_TYPE_NAME'] == 'Remote').astype(int)

# Summary statistics
print("summarydf")
summarydf = df_filtered[['AVG_SALARY', 'EXPERIENCE_YEARS', 'DURATION_DAYS']].describe()
summarydf.to_csv("./_output/Continuous_summary.csv")
```

## K-Means Clustering Analysis

Clustering helps us discover natural groupings in the job market. Different clusters might represent entry-level vs. senior positions, different specializations, or regional variations.


### Elbow Method for Optimal K

```{python}
#| fig-cap: "Elbow Method for Determining Optimal Number of Clusters"
#| echo: true
#| eval: false

# Prepare features for clustering
cluster_features = ['AVG_SALARY', 'EXPERIENCE_YEARS', 'DURATION_DAYS', 'IS_REMOTE']
df_cluster = df_filtered[cluster_features].dropna()

print(f"Clustering dataset: {len(df_cluster):,} samples")

# Standardize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(df_cluster)

# Elbow method
inertias = []
K_range = range(2, 11)

for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(X_scaled)
    inertias.append(kmeans.inertia_)

# Plot - smaller size
elbow_df = pd.DataFrame({'K': list(K_range), 'Inertia': inertias})

plt.figure(figsize=(8, 5))
sns.lineplot(data=elbow_df, x='K', y='Inertia', marker='o', 
             linewidth=2.5, markersize=10, color='#2196F3')
plt.xlabel('Number of Clusters (K)', fontsize=11, fontweight='bold')
plt.ylabel('Inertia', fontsize=11, fontweight='bold')
plt.title('Elbow Method for Optimal K', fontsize=13, fontweight='bold')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig("./_output/K-Means_clustering.png")
plt.show()

# print("\nInertia values by K:")
# print(elbow_df)
```

![K-Means Clustering for the Job Posting Data](./_output/K-Means_clustering.png){width=80% fig-align="center" #fig-kmeans}

ELBOW METHOD
The inertia drops sharply from 2 to 4 clusters, showing that most of the meaningful structure in the data is captured within this range. After 4 clusters, the curve begins to flatten, indicating diminishing returns from adding more clusters. This pattern suggests that K = 4 is the optimal and most efficient choice for segmenting the dataset
### Apply K-Means with Optimal K

```{python}
#| echo: true
#| eval: false

# Choose optimal K (typically where elbow occurs, around 3-4)
optimal_k = 4
scaler = StandardScaler()
X_scaled = scaler.fit_transform(df_cluster)
kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
df_cluster['Cluster'] = kmeans.fit_predict(X_scaled)

#print(f"\nClustering complete with K={optimal_k}")
#print("\nCluster distribution:")
#print(df_cluster['Cluster'].value_counts().sort_index())

# Analyze cluster characteristics
#print("\nCluster Characteristics:")
cluster_summary = df_cluster.groupby('Cluster').agg({
    'AVG_SALARY': ['mean', 'median'],
    'EXPERIENCE_YEARS': 'mean',
    'DURATION_DAYS': 'mean',
    'IS_REMOTE': 'mean'
}).round(2)

cluster_summary.to_csv("./_output/cluster_summary.csv")
print(cluster_summary)
```

Cluster 0 represents higher-paying roles with moderate experience requirements and shorter durations, mostly non-remote. Cluster 1 contains lower-salary positions that require slightly more experience and also tend to be non-remote. Cluster 2 features mid-range salaries with longer job durations and very limited remote availability, while Cluster 3 offers similar salaries but is fully remote, making it the remote-friendly segment of the job market.

```{python}
#| echo: true
#| eval: true

clst_sum = pd.read_csv("./_output/cluster_summary.csv")

clst_sum.style.hide(axis="index")
```

### PCA Visualization of Clusters

```{python}
#| fig-cap: "PCA Visualization of Job Clusters in BA/DS/ML Market"
#| fig-height: 5
#| echo: true
#| eval: false

# Apply PCA for visualization
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

df_cluster['PC1'] = X_pca[:, 0]
df_cluster['PC2'] = X_pca[:, 1]

# Create scatter plot with custom colors
plt.figure(figsize=(8, 5))
cluster_palette = ['#E91E63', '#9B59B6', '#F44336', '#2196F3']
sns.scatterplot(data=df_cluster, x='PC1', y='PC2', hue='Cluster', 
                palette=cluster_palette, s=60, alpha=0.7, 
                edgecolor='white', linewidth=0.3)
plt.xlabel('First Principal Component', fontsize=10, fontweight='bold')
plt.ylabel('Second Principal Component', fontsize=10, fontweight='bold')
plt.title(f'BA/DS/ML Job Clusters (K={optimal_k})', fontsize=11, fontweight='bold', pad=15)
plt.legend(title='Cluster', fontsize=9, title_fontsize=10, 
           frameon=True, fancybox=True, shadow=True)
plt.grid(True, alpha=0.2, linestyle='--')
plt.tight_layout()
plt.savefig("./_output/pca_plot.png")
plt.show()

#print(f"\nVariance explained:")
#print(f"PC1: {pca.explained_variance_ratio_[0]:.2%}")
#print(f"PC2: {pca.explained_variance_ratio_[1]:.2%}")
#print(f"Total: {sum(pca.explained_variance_ratio_):.2%}")
```

the first principal component explains 26.95% of the total variance and the second explains 25.08%, for a combined total of 52.03%. The PCA scatter plot maps the job postings onto these two components and shows four clusters formed using K-means (K=4), with each cluster occupying its own region despite some overlap.

![PCA for the Job Posting Data](./_output/pca_plot.png){width=80% fig-align="center" #fig-pca}


## Classification: Role Type Prediction

Understanding the distinguishing characteristics of different role types can help job seekers tailor their applications and skill development.

### Create Role Categories

```{python}
#| echo: true
#| eval: true

def categorize_role(title):
    """Categorize job titles into BA, DS, ML, or Data Analytics"""
    if pd.isna(title):
        return 'Other'
    title_lower = str(title).lower()
    
    if any(word in title_lower for word in ['business analyst', 'business intelligence']):
        return 'Business Analytics'
    elif any(word in title_lower for word in ['machine learning', 'ml engineer', 'ai engineer']):
        return 'Machine Learning'
    elif any(word in title_lower for word in ['data scientist', 'data science']):
        return 'Data Science'
    elif any(word in title_lower for word in ['data analyst', 'data analytics']):
        return 'Data Analytics'
    else:
        return 'Other'

# Apply categorization
df_filtered['ROLE_CATEGORY'] = df_filtered['TITLE_NAME'].apply(categorize_role)

# Filter to main categories
main_categories = ['Business Analytics', 'Data Science', 'Machine Learning', 'Data Analytics']
df_clf = df_filtered[df_filtered['ROLE_CATEGORY'].isin(main_categories)].copy()

#print(f"Classification dataset: {len(df_clf):,} samples")
#print("\nRole distribution:")
role_dist = df_clf['ROLE_CATEGORY'].value_counts()
#print(role_dist)
#print("\nPercentages:")
#print(role_dist / len(df_clf) * 100)
role_dist.to_csv("./_output/Role_Categories.csv")
print(role_dist)
```

```{python}
#| echo: true
#| eval: true

class_sum = pd.read_csv("./_output/Role_Categories.csv")

class_sum.style.hide(axis="index")
```

### Prepare Classification Features

```{python}
#| echo: true
#| eval: true

# Get top states
top_states = df_clf['STATE_NAME'].value_counts().head(10).index

# Prepare features for classification
clf_feature_cols = ['EXPERIENCE_YEARS', 'DURATION_DAYS', 'IS_REMOTE', 'AVG_SALARY']

# Add state features
for state in top_states:
    col_name = f'STATE_{state}'
    df_clf[col_name] = (df_clf['STATE_NAME'] == state).astype(int)
    clf_feature_cols.append(col_name)

# Prepare X and y
X_clf = df_clf[clf_feature_cols].fillna(0)
y_clf = df_clf['ROLE_CATEGORY']

#print(f"Classification features: {len(clf_feature_cols)}")
#print(f"Samples per class:")
#print(y_clf.value_counts())

# Save feature columns as DataFrame
pd.DataFrame(clf_feature_cols, columns=['feature']).to_csv("./_output/clf_feature_cols.csv", index=False)
print(clf_feature_cols)

# Train-test split
X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(
    X_clf, y_clf, test_size=0.3, random_state=42, stratify=y_clf
)

# Scale features
scaler_clf = StandardScaler()
X_train_clf_scaled = scaler_clf.fit_transform(X_train_clf)
X_test_clf_scaled = scaler_clf.transform(X_test_clf)
```

```{python}
#| echo: true
#| eval: true

clf_feature = pd.read_csv("./_output/clf_feature_cols.csv")

clf_feature.style.hide(axis="index")
```

### Logistic Regression Classification

```{python}
#| echo: true
#| eval: true

# Train logistic regression
lr = LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial')
lr.fit(X_train_clf_scaled, y_train_clf)
y_pred_lr = lr.predict(X_test_clf_scaled)
y_pred_proba_lr = lr.predict_proba(X_test_clf_scaled)

# Calculate metrics
acc_lr = accuracy_score(y_test_clf, y_pred_lr)
f1_lr = f1_score(y_test_clf, y_pred_lr, average='weighted')

#print("LOGISTIC REGRESSION CLASSIFICATION")
#print("=" * 50)
#print(f"Accuracy: {acc_lr:.4f} ({acc_lr*100:.2f}%)")
#print(f"F1 Score (Weighted): {f1_lr:.4f}")
#print("\nClassification Report:")
#print(classification_report(y_test_clf, y_pred_lr))

# Save metrics as DataFrames
pd.DataFrame({'accuracy': [acc_lr]}).to_csv("./_output/accuracy.csv", index=False)
pd.DataFrame({'f1_score': [f1_lr]}).to_csv("./_output/f1.csv", index=False)
#print(f"Accuracy: {acc_lr:.4f}")
#print(f"F1 Score: {f1_lr:.4f}")
```

```{python}
#| echo: true
#| eval: true

acc = pd.read_csv("./_output/accuracy.csv")
acc.style.hide(axis="index")
```

```{python}
#| echo: true
#| eval: true

f1 = pd.read_csv("./_output/f1.csv")
f1.style.hide(axis="index")
```

The logistic regression model reaches 84% accuracy, but this is mainly because it predicts most entries as “Data Analytics,” the largest class in the dataset. While the model performs well for this category, it struggles to recognize smaller roles like Business Analytics, Data Science, and Machine Learning, which show very low recall and F1-scores. This imbalance means the model is not effectively distinguishing minority roles and is primarily learning from the dominant class rather than providing balanced prediction

### Random Forest Classification

```{python}
#| echo: true
#| eval: true

# Train random forest classifier
rf_clf = RandomForestClassifier(n_estimators=100, max_depth=15, 
                                min_samples_split=10, random_state=42, n_jobs=-1)
rf_clf.fit(X_train_clf, y_train_clf)
y_pred_rf_clf = rf_clf.predict(X_test_clf)
y_pred_proba_rf = rf_clf.predict_proba(X_test_clf)

# Calculate metrics
acc_rf_clf = accuracy_score(y_test_clf, y_pred_rf_clf)
f1_rf_clf = f1_score(y_test_clf, y_pred_rf_clf, average='weighted')

#print("RANDOM FOREST CLASSIFICATION")
#print("=" * 50)
#print(f"Accuracy: {acc_rf_clf:.4f} ({acc_rf_clf*100:.2f}%)")
#print(f"F1 Score (Weighted): {f1_rf_clf:.4f}")
#print("\nClassification Report:")
#print(classification_report(y_test_clf, y_pred_rf_clf))

# Save metrics as DataFrames
pd.DataFrame({'accuracy': [acc_rf_clf]}).to_csv("./_output/accuracy_rf.csv", index=False)
pd.DataFrame({'f1_score': [f1_rf_clf]}).to_csv("./_output/f1_rf.csv", index=False)
#print(f"Accuracy: {acc_rf_clf:.4f}")
#print(f"F1 Score: {f1_rf_clf:.4f}")
```

```{python}
#| echo: true
#| eval: true

acc_random = pd.read_csv("./_output/accuracy_rf.csv")
acc_random.style.hide(axis="index")
```

```{python}
#| echo: true
#| eval: true

f1_random = pd.read_csv("./_output/f1_rf.csv")
f1_random.style.hide(axis="index")
```

The model reaches a high overall accuracy of 85.6%, but this is influenced by the extreme class imbalance in the dataset. It predicts the dominant Data Analytics category very well, yet performs poorly on the smaller groups -Business Analytics, Data Science, and Machine Learning which is leading to a low  F1 score of 0.33. This shows that the model is not generalizing effectively across all role types. To achieve more balanced and reliable results, techniques such as oversampling, class weighting, or rebalancing the dataset would be needed.

### Classification Model Comparison

```{python}
#### ROC Curves - Logistic Regression
#| fig-cap: "Logistic Regression ROC Curves"
#| echo: true
#| eval: true

# Binarize labels for ROC curve
classes = lr.classes_
y_test_bin = label_binarize(y_test_clf, classes=classes)
n_classes = len(classes)

# Color palette for classes
colors = cycle(['#E91E63', '#9B59B6', '#F44336', '#2196F3'])

# Create figure
plt.figure(figsize=(8, 6))

for i, color, class_name in zip(range(n_classes), colors, classes):
    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_pred_proba_lr[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, color=color, lw=2.5, 
            label=f'{class_name} (AUC = {roc_auc:.3f})')

plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Chance (AUC = 0.500)')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate', fontsize=12, fontweight='bold')
plt.ylabel('True Positive Rate', fontsize=12, fontweight='bold')
plt.title('Logistic Regression: ROC Curves', fontsize=14, fontweight='bold', pad=15)
plt.legend(loc="lower right", fontsize=10, frameon=True, fancybox=True, shadow=True)
plt.grid(True, alpha=0.3, linestyle='--')
ax = plt.gca()
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
plt.tight_layout()
plt.savefig("./_output/roc_lr.png", dpi=300, bbox_inches='tight')
plt.show()
```

 The ROC curves show that the logistic regression model has moderate ability to distinguish between the different role categories, with AUC scores ranging from 0.58 to 0.77. Machine Learning achieves the highest AUC (0.775), suggesting the model can separate this class reasonably well despite its tiny sample size, while Data Science has the weakest separability (0.585). Overall, the curves indicate that the classifier performs above random chance for all roles but still struggles to clearly differentiate between them, reflecting the impact of class imbalance and overlapping feature patterns.

#### ROC Curves - Random Forest

```{python}
#| fig-cap: "Random Forest ROC Curves"
#| echo: true
#| eval: true

# Create figure
plt.figure(figsize=(8, 6))

colors = cycle(['#E91E63', '#9B59B6', '#F44336', '#2196F3'])
for i, color, class_name in zip(range(n_classes), colors, classes):
    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_pred_proba_rf[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, color=color, lw=2.5, 
            label=f'{class_name} (AUC = {roc_auc:.3f})')

plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Chance (AUC = 0.500)')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate', fontsize=12, fontweight='bold')
plt.ylabel('True Positive Rate', fontsize=12, fontweight='bold')
plt.title('Random Forest: ROC Curves', fontsize=14, fontweight='bold', pad=15)
plt.legend(loc="lower right", fontsize=10, frameon=True, fancybox=True, shadow=True)
plt.grid(True, alpha=0.3, linestyle='--')
ax = plt.gca()
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
plt.tight_layout()
plt.savefig("./_output/roc_rf.png", dpi=300, bbox_inches='tight')
plt.show()
```

The Random Forest model shows improved class separability compared to logistic regression, with AUC values ranging from 0.60 to 0.84. Machine Learning achieves the strongest performance (AUC = 0.842), indicating the model can distinguish this role well despite its tiny sample size. Business Analytics and Data Analytics also show moderate discrimination, while Data Science remains the most challenging class, reflecting overlapping features and limited data representation.

#### Model Performance Comparison

```{python}
#| fig-cap: "Model Performance Comparison"
#| echo: true
#| eval: true

comparison_df = pd.DataFrame({
    'Model': ['Logistic Regression', 'Random Forest'],
    'Accuracy': [acc_lr, acc_rf_clf],
    'F1 Score': [f1_lr, f1_rf_clf]
})

plt.figure(figsize=(8, 6))
x = np.arange(len(comparison_df['Model']))
width = 0.35

bars1 = plt.bar(x - width/2, comparison_df['Accuracy'], width, 
               label='Accuracy', color='#E91E63', alpha=0.8, edgecolor='white', linewidth=1.5)
bars2 = plt.bar(x + width/2, comparison_df['F1 Score'], width, 
               label='F1 Score', color='#9B59B6', alpha=0.8, edgecolor='white', linewidth=1.5)

plt.ylabel('Score', fontsize=12, fontweight='bold')
plt.xlabel('Model', fontsize=12, fontweight='bold')
plt.title('Model Performance Comparison', fontsize=14, fontweight='bold', pad=15)
plt.xticks(x, comparison_df['Model'])
plt.legend(fontsize=10, frameon=True, fancybox=True, shadow=True)
plt.ylim([0, 1.1])
plt.grid(True, alpha=0.3, axis='y', linestyle='--')
ax = plt.gca()
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)

# Add value labels on bars
for bars in [bars1, bars2]:
    for bar in bars:
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')

plt.tight_layout()
plt.savefig("./_output/model_comparison.png", dpi=300, bbox_inches='tight')
plt.show()
```

The comparison shows that Random Forest outperforms Logistic Regression, achieving both higher accuracy (85.6%) and a stronger F1 score (0.815). This indicates that Random Forest handles the complex and imbalanced role categories more effectively. Overall, while both models perform well, Random Forest delivers more balanced and reliable predictions across the dataset.

#### Feature Importance Analysis

```{python}
#| fig-cap: "Top 10 Predictive Features (Random Forest)"
#| echo: true
#| eval: true

clf_importance = pd.DataFrame({
    'Feature': clf_feature_cols,
    'Importance': rf_clf.feature_importances_
}).sort_values('Importance', ascending=False).head(10)

plt.figure(figsize=(8, 6))
bars = plt.barh(range(len(clf_importance)), clf_importance['Importance'], 
               color=['#E91E63', '#9B59B6', '#F44336', '#2196F3'] * 3, 
               alpha=0.8, edgecolor='white', linewidth=1.5)
plt.yticks(range(len(clf_importance)), clf_importance['Feature'])
plt.xlabel('Feature Importance', fontsize=12, fontweight='bold')
plt.title('Top 10 Predictive Features (Random Forest)', fontsize=14, fontweight='bold', pad=15)
plt.grid(True, alpha=0.3, axis='x', linestyle='--')
ax = plt.gca()
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)

# Add value labels
for i, bar in enumerate(bars):
    width = bar.get_width()
    plt.text(width, bar.get_y() + bar.get_height()/2.,
            f'{width:.3f}', ha='left', va='center', fontsize=9, fontweight='bold')

plt.tight_layout()
plt.savefig("./_output/feature_importance.png", dpi=300, bbox_inches='tight')
plt.show()
```

The feature importance results show that *experience years, average salary, and job duration are the strongest predictors in distinguishing between BA, Data Science, ML, and Data Analytics roles. Remote status contributes modestly, while location-based features (state variables) have minimal impact, indicating that job role differences are driven more by skill level and job characteristics than by geography. Overall, the model relies most heavily on experience and salary patterns to differentiate job categories.