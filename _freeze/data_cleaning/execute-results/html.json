{
  "hash": "7fa52023d3db8d35ed5b31103f00b27c",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Data Cleaning & Exploration\"\nsubtitle: \"Preparing the Job Market Dataset for Analysis\"\nauthor:\n  - name: Tuba Anwar\n  - name: Kriti Singh\n  - name: Soham Deshkhaire\nformat: \n  html:\n    toc: true\n    number-sections: true\n    df-print: paged\n    code-overflow: wrap\n    embed-resources: true\n    theme: cosmo\njupyter: python3\nexecute:\n  echo: false\n  warning: false\n  message: false\n---\n\n## Introduction\n\nThis document details the comprehensive data cleaning and preprocessing steps applied to the 2024 job market dataset.\n\n::: {#ca25eff0 .cell execution_count=1}\n\n::: {.cell-output .cell-output-stdout}\n```\nInitial dataset shape: (72498, 131)\nTotal rows: 72,498\nTotal columns: 131\n```\n:::\n:::\n\n\n## Step 1: Removing Redundant Columns\n\nWe remove redundant columns to improve dataset quality and analysis efficiency.\n\n::: {#4ccea486 .cell execution_count=2}\n\n::: {.cell-output .cell-output-stdout}\n```\nColumns removed: 69\nNew dataset shape: (72498, 62)\n```\n:::\n:::\n\n\n## Step 2: Handling Missing Values\n\n::: {#6d6bdbfd .cell execution_count=3}\n\n::: {.cell-output .cell-output-stdout}\n```\nColumns with missing values: 62\n\nTop 10 columns with highest missing percentages:\n                    Column  Missing_Count  Missing_Percentage\n18    MAX_YEARS_EXPERIENCE          64068               88.37\n13           MAX_EDULEVELS          56183               77.50\n14      MAX_EDULEVELS_NAME          56183               77.50\n50       LIGHTCAST_SECTORS          54711               75.47\n51  LIGHTCAST_SECTORS_NAME          54711               75.47\n20                  SALARY          41690               57.51\n3                 DURATION          27316               37.68\n17    MIN_YEARS_EXPERIENCE          23146               31.93\n2                  EXPIRED           7844               10.82\n30       MSA_NAME_INCOMING           3962                5.46\n```\n:::\n:::\n\n\n::: {#e664fb26 .cell execution_count=4}\n\n::: {.cell-output .cell-output-stdout}\n```\nColumns dropped due to >50% missing values: 6\nTotal missing values after imputation: 0\n```\n:::\n:::\n\n\n## Step 3: Removing Duplicates\n\n::: {#24594352 .cell execution_count=5}\n\n::: {.cell-output .cell-output-stdout}\n```\nInitial rows: 72,498\nDuplicate rows detected: 13,278\nFinal rows after duplicate removal: 59,220\nRows removed: 13,278\n```\n:::\n:::\n\n\n## Step 4: Final Summary\n\n::: {#93b968c0 .cell execution_count=6}\n\n::: {.cell-output .cell-output-stdout}\n```\n             Metric  Value\n         Total Rows 59,220\n      Total Columns     56\n  Numerical Columns     12\nCategorical Columns     44\n     Missing Values      0\n\nCleaned dataset saved as 'cleanedjob_postings.csv'\n```\n:::\n:::\n\n\n## Summary\n\nThe data cleaning process has successfully prepared the job market dataset:\n\n- Removed redundant columns\n- Handled missing values strategically\n- Removed duplicate postings\n- Final clean dataset ready for analysis\n\n",
    "supporting": [
      "data_cleaning_files"
    ],
    "filters": [],
    "includes": {}
  }
}